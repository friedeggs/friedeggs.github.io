<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Papers on frieda rong</title>
    <link>http://friedeggs.github.io/papers/</link>
    <description>Recent content in Papers on frieda rong</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© 2019–2023</copyright>
    <lastBuildDate>Sat, 07 Oct 2023 21:10:48 -0400</lastBuildDate><atom:link href="http://friedeggs.github.io/papers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Value Internalization: Learning and Generalizing from Social Reward</title>
      <link>http://friedeggs.github.io/papers/social-play/</link>
      <pubDate>Sat, 07 Oct 2023 21:10:48 -0400</pubDate>
      
      <guid>http://friedeggs.github.io/papers/social-play/</guid>
      <description>Accepted to CogSci 2024.
How can AI agents learn intrinsic motivations from others and internalise social rewards?</description>
    </item>
    
    <item>
      <title>Reinforcement Learning Models of Tradeoffs Between Infant Attachment and Curiosity</title>
      <link>http://friedeggs.github.io/papers/attachment-agents/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/attachment-agents/</guid>
      <description>Member abstract at CogSci 2023.
How can we computationally model infant learning and attachment styles?</description>
    </item>
    
    <item>
      <title>Characterizing Learning Progress of Problem-Solvers Using Puzzle-Solving Log Data</title>
      <link>http://friedeggs.github.io/papers/learning-progress/</link>
      <pubDate>Fri, 20 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/learning-progress/</guid>
      <description>Demo paper at EDM 2023.
How do human learners perform on a puzzle video game compared to AI learners?</description>
    </item>
    
    <item>
      <title>Evaluating Human-Language Model Interaction</title>
      <link>http://friedeggs.github.io/papers/halie/</link>
      <pubDate>Mon, 19 Dec 2022 01:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/halie/</guid>
      <description>Accepted to TMLR 2023
How can we use AI assistants to generate metaphors?</description>
    </item>
    
    <item>
      <title>Holistic Evaluation of Language Models</title>
      <link>http://friedeggs.github.io/papers/helm/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/helm/</guid>
      <description>†: lead authors
*: major contributors  endpreamble
Accepted to TMLR 2023.
How well do large language models perform on the MATH dataset?</description>
    </item>
    
    <item>
      <title>Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models</title>
      <link>http://friedeggs.github.io/papers/big-bench/</link>
      <pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/big-bench/</guid>
      <description>Accepted to TMLR 2023.
How well do large language models perform on an unnatural in-context learning task?</description>
    </item>
    
    <item>
      <title>On the Opportunities and Risks of Foundation Models</title>
      <link>http://friedeggs.github.io/papers/foundation-models/</link>
      <pubDate>Mon, 16 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/foundation-models/</guid>
      <description>Please cite using these guidelines.
endpreamble
What are the next steps in teaching foundation models formal reasoning and using them?</description>
    </item>
    
    <item>
      <title>GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving</title>
      <link>http://friedeggs.github.io/papers/geosim/</link>
      <pubDate>Sat, 16 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://friedeggs.github.io/papers/geosim/</guid>
      <description>Best Paper Candidate at CVPR 2021
How do we combine the best of graphics-based simulation and neural rendering?</description>
    </item>
    
  </channel>
</rss>
